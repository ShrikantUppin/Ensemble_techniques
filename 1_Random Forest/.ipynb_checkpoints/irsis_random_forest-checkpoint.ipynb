{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lux\n",
    "import sweetviz\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Dataset loading & Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data = iris.data, columns = iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1320effaa645ca83ada495a49636fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa9a332c28f4045809c5a9c949a448a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07724c0cc44d56a25046f1cc7dfd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b17579385574dbda977f288d4f3e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data = iris.target, columns = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above plot shows there is equal distribution of data for each target variable label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bookmarked_charts = y.exported  # for this we need to first export required chart from lux toggle\n",
    "# bookmarked_charts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y):\n",
    "    \n",
    "    # setting required variables to the global so that they can be accessed outside of function\n",
    "    global x_train, x_test, y_train, y_test\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33,\\\n",
    "                                                        random_state=42, stratify = y)\n",
    "\n",
    "    #checking target variable data % equal in y_train & y_test\n",
    "    print('checking tarfet label count balance in y_train & y_test')\n",
    "    print('-'*40)\n",
    "    print(y_test.value_counts(normalize=True))\n",
    "    print('-'*40)\n",
    "    print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_alpha(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    ccp_alphas = np.arange(0.000, 0.040, 0.002)\n",
    "    clfs = []\n",
    "    for ccp_alpha in ccp_alphas:\n",
    "        clf = RandomForestClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "        clf.fit(x_train, y_train)\n",
    "        clfs.append(clf)\n",
    "  \n",
    "    train_scores = [clf.score(x_train, y_train) for clf in clfs]\n",
    "    test_scores = [clf.score(x_test, y_test) for clf in clfs]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.set_xlabel(\"alpha\")\n",
    "    ax.set_ylabel(\"accuracy\")\n",
    "    ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "    ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "            drawstyle=\"steps-post\")\n",
    "    ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "            drawstyle=\"steps-post\")\n",
    "    ax.set_xticks(np.arange(0.000,0.040, 0.002))\n",
    "    ax.set_yticks(np.arange(0.88,1.01, 0.01))\n",
    "    ax.legend()\n",
    "    plt.grid(True)\n",
    "    plt.rcParams['xtick.labelsize']=12\n",
    "    plt.rcParams['ytick.labelsize']=12\n",
    "    plt.show()\n",
    "\n",
    "find_alpha(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ccp_alpha=0.014 gives best accuracy for train & test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Model Building..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    ccp_alpha_value = float(input('enter ccp_alpha value:'))\n",
    "    print()\n",
    "    \n",
    "    # importing required libraries\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # creating classifier object/instance\n",
    "    global model\n",
    "    model = RandomForestClassifier(random_state=42, ccp_alpha = ccp_alpha_value)\n",
    "    \n",
    "    # fit model on train datasets\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # train & test scores i.e. accuracy\n",
    "    train_score = model.score(x_train, y_train)\n",
    "    test_score = model.score(x_test, y_test)\n",
    "    \n",
    "    # model prediction on x_train & x_test dataset\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test  = model.predict(x_test)\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_cm = confusion_matrix(y_train, y_pred_train)\n",
    "    test_cm = confusion_matrix(y_test, y_pred_test)\n",
    "    \n",
    "    # classification report\n",
    "    train_classification = classification_report(y_train, y_train)\n",
    "    test_classification = classification_report(y_test, y_test)\n",
    "    \n",
    "    # TRAIN DATA OUTPUTS..\n",
    "    print('train_score:', train_score)\n",
    "    print()\n",
    "    \n",
    "    print('CONFUSION MATRIX FOR TRAIN DATA')\n",
    "    figure1, ax1 = plt.subplots(1,1)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(train_cm, annot=True, ax = ax1)\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    print('Classification report for train data')\n",
    "    print(train_classification)\n",
    "    print('-'*60)\n",
    "    \n",
    "     # TEST DATA OUTPUTS..\n",
    "    print('test_score:', test_score)\n",
    "    print()\n",
    "    print('CONFUSION MATRIX FOR TEST DATA')\n",
    "    figure, ax2 = plt.subplots(1,1)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(test_cm, annot=True, ax = ax2)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Classification report for test data')\n",
    "    print(test_classification)\n",
    "    print('-'*60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_build(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Model cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cross_validation(x, y, cv=5):\n",
    "\n",
    "    from sklearn import metrics\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    scores = cross_val_score(model, x, y, cv=5)\n",
    "\n",
    "    print(scores)\n",
    "    print()\n",
    "    print('The mean score and the 95% confidence interval of the score estimate:')\n",
    "    print()\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cross_validation(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
